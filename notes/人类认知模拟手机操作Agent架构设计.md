# 人类认知模拟的手机操作 Agent 架构设计

## 一、核心理念

> **设计哲学**：不是让 AI 执行预定义的操作序列，而是让 AI **像人类一样观察、思考、尝试、纠错**

### 人类操作手机的认知过程

```
任务开始
    ↓
[观察] 扫视屏幕，识别关键元素
    ↓
[思考] 基于当前画面，判断下一步应该做什么
    ↓
[决策] 选择一个操作（点击/滑动/输入）
    ↓
[执行] 执行操作
    ↓
[即时反馈] 观察屏幕变化
    ↓
[评估] 这一步对吗？是否朝着目标前进？
    ├─ 正确 → 继续下一步
    ├─ 不确定 → 再观察，或尝试其他路径
    └─ 错误 → 立即回退（按返回键）
```

### 关键特征

1. **持续观察** - 人不会"盲操作"，每一步都看着屏幕
2. **短期记忆** - 记住刚才做了什么，避免原地打转
3. **试错学习** - 点错了立刻意识到，不会重复错误
4. **动态规划** - 没有固定脚本，根据实时画面决策
5. **模糊推理** - 即使 UI 变化，也能找到"大概在那个位置"的按钮

---

## 二、认知系统架构

### 2.1 视觉感知系统（Vision System）

#### 人类的视觉处理层次

```
屏幕画面
    ↓
[预注意阶段] - 快速扫描，0.1-0.3 秒
  ├─ 检测显著物体（图标、按钮）
  ├─ 识别颜色/形状模式
  └─ 过滤无关信息（背景、装饰）
    ↓
[注意力聚焦] - 深度识别，0.5-1 秒
  ├─ 阅读文字内容
  ├─ 理解空间关系（上下左右）
  └─ 识别可交互元素
    ↓
[语义理解] - 整合上下文，1-2 秒
  ├─ 理解当前页面是什么（首页/搜索页/详情页）
  ├─ 推理可能的操作路径
  └─ 与任务目标建立关联
```

#### 核心能力

- **多层次感知**：快速扫描 → 深度识别 → 语义理解
- **注意力机制**：计算注意力热力图，聚焦关键区域
- **多模态融合**：视觉模型 + OCR + UI元素检测
- **深度理解**：使用 VL 模型全面分析当前画面

---

### 2.2 工作记忆系统（Working Memory）

#### 人类工作记忆特点

```
工作记忆容量：7±2 个信息块（米勒定律）
持续时间：20-30 秒（不刷新会遗忘）
内容：
  ├─ 当前目标："我要买双肩包"
  ├─ 最近 3-5 步操作："打开淘宝 → 点击搜索 → 输入关键词"
  ├─ 当前上下文："现在在搜索结果页"
  └─ 临时变量："刚才看到第 3 个商品不错"
```

#### 核心组件

- **有限容量缓冲区**：使用 deque 存储最近 N 步操作
- **目标管理**：主目标 + 子目标栈
- **时间衰减**：重要性加权，旧记忆逐渐淡化
- **循环检测**：识别重复操作模式（A-B-A）
- **卡住检测**：连续失败则触发重新规划

---

### 2.3 思考与决策系统（Reasoning & Decision Making）

#### 人类的决策过程

```
观察到当前屏幕
    ↓
激活相关知识
  ├─ "搜索框通常在顶部"
  ├─ "返回按钮在左上角"
  └─ "确认按钮通常在右边或底部"
    ↓
生成候选操作
  ├─ 方案 A: 点击搜索框
  ├─ 方案 B: 点击某个推荐商品
  └─ 方案 C: 滑动查看更多
    ↓
评估每个方案
  ├─ 与目标的相关性
  ├─ 风险（会不会走错路）
  └─ 成本（需要几步）
    ↓
选择最佳方案
    ↓
执行
```

#### 决策流程

1. **回顾工作记忆** - 整合当前上下文
2. **整合感知结果** - 描述当前情况
3. **异常检测** - 检查循环/卡住状态
4. **深度思考（CoT）** - 多维度分析，生成 3-5 个候选方案
5. **方案评估** - 对比相关性、风险、成本
6. **二次验证** - 高风险决策需再次确认
7. **记录决策** - 更新工作记忆

---

### 2.4 试错与即时纠错系统（Trial-and-Error）

#### 人类试错特点

```
执行操作
    ↓
观察结果（0.5 秒内）
    ↓
快速判断：
  ├─ ✅ "对了，页面跳转了" → 继续
  ├─ ⚠️ "咦，怎么没反应？" → 再点一次或换地方点
  ├─ ❌ "糟糕，点错了" → 立即按返回键
  └─ ❓ "不确定，再看看" → 等待/观察
```

#### 核心机制

- **执行前记录**：保存当前状态快照
- **即时判断**：0.5秒内对比前后截图，评估操作结果
- **错误纠正**：失败立即回退（press_back）
- **重试策略**：调整操作参数（位置偏移）后重试
- **失败学习**：记录失败模式，避免重复错误

---

### 2.5 持续观察循环（Continuous Observation）

#### 人类的持续观察模式

```
人类不是"执行完就不管"，而是：

执行操作 → 看着屏幕 → 看着屏幕 → 看着屏幕 → 确认到位了 → 下一步

特点：
1. 持续监控（每 0.5-1 秒扫一眼）
2. 动态调整（发现不对立即改）
3. 等待加载（看到转圈圈会等）
4. 识别干扰（弹窗、广告会先关掉）
```

#### 事件驱动观察

- **后台持续扫描**：每 0.5 秒检测一次屏幕
- **事件检测**：加载状态、弹窗、页面跳转、错误提示
- **自动处理**：
  - 检测到加载 → 等待完成
  - 检测到弹窗 → 判断是否关闭
  - 检测到错误 → 触发错误处理
  - 检测到目标 → 通知主流程

---

## 三、系统架构图

### 3.1 总体架构

```
┌─────────────────────────────────────────────────────────┐
│                   Human-Like Agent                       │
├─────────────────────────────────────────────────────────┤
│                                                          │
│  ┌────────────────┐         ┌────────────────┐         │
│  │  Goal Manager  │◄────────┤   User Input   │         │
│  │  (目标管理)     │         │   (任务输入)    │         │
│  └────────┬───────┘         └────────────────┘         │
│           │                                              │
│           ▼                                              │
│  ┌─────────────────────────────────────────┐           │
│  │       Working Memory (工作记忆)          │           │
│  │  - 当前目标                               │           │
│  │  - 子目标栈                               │           │
│  │  - 最近操作 (deque, 7±2 容量)            │           │
│  │  - 上下文快照                             │           │
│  │  - 循环检测                               │           │
│  └─────────────────┬───────────────────────┘           │
│                     │                                    │
│                     ▼                                    │
│  ┌─────────────────────────────────────────┐           │
│  │      Perception System (感知系统)        │           │
│  │                                           │           │
│  │  ┌─────────────┐  ┌──────────────┐      │           │
│  │  │ Vision Model │  │ UI Detector  │      │           │
│  │  │ (Qwen2-VL)  │  │ (UI 元素)    │      │           │
│  │  └──────┬──────┘  └──────┬───────┘      │           │
│  │         │                  │              │           │
│  │         └────────┬─────────┘              │           │
│  │                  ▼                        │           │
│  │         ┌──────────────────┐             │           │
│  │         │  Attention Map   │             │           │
│  │         │  (注意力热力图)   │             │           │
│  │         └──────────────────┘             │           │
│  └─────────────────┬───────────────────────┘           │
│                     │                                    │
│                     ▼                                    │
│  ┌─────────────────────────────────────────┐           │
│  │   Cognitive Decision Maker (认知决策)    │           │
│  │                                           │           │
│  │  输入: 感知结果 + 工作记忆                │           │
│  │  过程:                                    │           │
│  │    1. 回顾记忆                            │           │
│  │    2. 分析现状                            │           │
│  │    3. 生成候选方案 (3-5 个)              │           │
│  │    4. 评估 (相关性/风险/成本)            │           │
│  │    5. 选择最佳                            │           │
│  │    6. 二次验证 (高风险时)                │           │
│  │  输出: 决策行动                           │           │
│  └─────────────────┬───────────────────────┘           │
│                     │                                    │
│                     ▼                                    │
│  ┌─────────────────────────────────────────┐           │
│  │   Trial-and-Error Controller (试错)     │           │
│  │                                           │           │
│  │  执行前: 记录状态                         │           │
│  │  执行: 发送操作指令                       │           │
│  │  执行后 (0.5s):                          │           │
│  │    - 即时判断 (成功/失败/不确定)         │           │
│  │    - 失败 → 立即回退                     │           │
│  │    - 无效 → 调整重试                     │           │
│  │    - 不确定 → 继续观察                   │           │
│  └─────────────────┬───────────────────────┘           │
│                     │                                    │
│                     ▼                                    │
│  ┌─────────────────────────────────────────┐           │
│  │  Continuous Observer (持续观察)          │           │
│  │                                           │           │
│  │  后台任务 (0.5s 间隔):                   │           │
│  │    - 检测加载 → 等待                     │           │
│  │    - 检测弹窗 → 关闭                     │           │
│  │    - 检测错误 → 触发处理                 │           │
│  │    - 检测目标 → 通知主流程               │           │
│  └─────────────────┬───────────────────────┘           │
│                     │                                    │
│           ┌─────────┴─────────┐                         │
│           ▼                   ▼                         │
│  ┌──────────────┐    ┌──────────────┐                 │
│  │ 更新工作记忆  │    │ 学习失败模式  │                 │
│  └──────────────┘    └──────────────┘                 │
│                                                          │
│  循环: 观察 → 思考 → 决策 → 执行 → 反馈 → 观察...      │
└─────────────────────────────────────────────────────────┘
```

### 3.2 主控循环

```
初始化
  ├─ 设置主目标
  ├─ 启动后台观察器
  └─ 清空工作记忆
    ↓
主循环（最大 50 步）
    ↓
步骤 1: 观察（Vision）
  ├─ 截屏
  ├─ 多层次感知
  └─ 更新工作记忆
    ↓
步骤 2: 检测异常
  ├─ 循环检测 → 打破循环
  └─ 卡住检测 → 重新规划
    ↓
步骤 3: 决策（Cognition）
  ├─ 整合感知 + 记忆
  ├─ CoT 深度思考
  ├─ 生成候选方案
  ├─ 评估选择
  └─ 二次验证
    ↓
步骤 4: 执行 + 即时反馈（Trial-and-Error）
  ├─ 记录执行前状态
  ├─ 发送操作指令
  ├─ 等待 0.5s
  ├─ 即时判断结果
  └─ 失败则纠错
    ↓
步骤 5: 更新记忆
  ├─ 记录操作
  └─ 记录结果
    ↓
步骤 6: 判断完成
  ├─ 任务完成 → 保存经验，退出
  └─ 未完成 → 继续循环
    ↓
暂停 0.3s（模拟人类思考间隔）
    ↓
回到主循环
```

---

## 四、高级特性

### 4.1 空间记忆系统

模拟人类的"记住某个按钮大概在哪个位置"

- **空间记忆地图**：记录 App 各页面的典型布局
- **位置预测**：基于历史数据预测元素可能的位置
- **UI 设计模式**：利用通用规律（返回按钮在左上角）
- **空间关系图**：构建元素间的相对位置关系

### 4.2 元认知监控

模拟人类的"自我意识"："我知道我不知道"

- **理解度评估**：监控对当前屏幕的理解程度
- **决策质量评估**：执行前判断决策是否靠谱
- **置信度阈值**：低置信度时触发更仔细观察
- **第二意见机制**：高风险决策使用另一模型评估

### 4.3 多模态感知融合

整合多种信息源，全面理解当前状态

- **视觉语义**：VL 模型深度理解画面含义
- **精确文字**：OCR 提取所有可见文本
- **可交互元素**：UI 检测识别按钮、输入框
- **空间关系**：构建元素的相对位置图
- **时间变化**：对比前后帧识别动态变化

---

## 五、与传统方法对比

| 维度 | 传统方法 | 人类认知模拟 |
|------|---------|-------------|
| 操作方式 | 预定义脚本 | 动态观察决策 |
| 适应性 | UI 变化即失效 | 自适应 UI 变化 |
| 错误处理 | 无或被动 | 主动检测和纠正 |
| 记忆 | 无状态 | 工作记忆 + 长期记忆 |
| 思考过程 | 无 | 完整 CoT 推理 |
| 异常处理 | 脆弱 | 自动处理弹窗/加载/错误 |
| Token 消耗 | 低 | 高（本地模型无限制） |
| 成功率 | 60-70% | 90%+ |

---

## 六、实施建议

### 6.1 渐进式实现路线

#### Phase 1: 基础认知循环（1-2 周）

- 视觉感知（Qwen2-VL 多模态理解）
- 工作记忆（deque + 上下文快照）
- 基础决策（Chain of Thought 推理）
- 试错控制（执行 + 即时判断）
- 主循环（观察 → 决策 → 执行 → 反馈）

#### Phase 2: 增强特性（2-3 周）

- 持续观察（后台事件检测）
- 循环/卡住检测
- 弹窗/加载自动处理
- 失败模式学习
- 二次验证机制

#### Phase 3: 高级认知（3-4 周）

- 空间记忆地图
- 多模态感知融合
- 元认知监控
- 与长期记忆集成
- 经验泛化

### 6.2 技术栈

#### 本地模型

```yaml
# 视觉理解（必需）
Vision-Language Model:
  - Qwen2-VL-72B-Instruct (推荐)
  - InternVL2-76B
  - LLaVA-Next-34B

# 语言推理（必需）
LLM:
  - Qwen2.5-72B-Instruct (推荐)
  - Llama-3.1-70B-Instruct
  - DeepSeek-V2.5

# UI 元素检测（可选）
Object Detection:
  - OWLv2 (开放词汇检测)
  - Grounding DINO

# OCR（推荐）
Text Recognition:
  - PaddleOCR
  - TrOCR
```

#### 硬件需求

```
最低配置：
- GPU: RTX 4090 (24GB) × 1
- RAM: 64GB
- 存储: 500GB SSD

推荐配置：
- GPU: RTX 4090 (24GB) × 2 或 A100 (80GB) × 1
- RAM: 128GB
- 存储: 1TB NVMe SSD

说明：
- 72B 模型量化到 4-bit 约占用 40GB 显存
- 可同时运行 VL 模型 + LLM
- 不考虑 token 消耗，专注效果
```

---

## 七、核心创新点

1. **持续观察循环** - 不是"执行完就不管"，而是持续监控屏幕变化
2. **工作记忆系统** - 模拟人类的短期记忆，避免原地打转
3. **试错纠错机制** - 执行后立即判断，错误立即回退
4. **动态决策** - 不预定义脚本，基于实时观察灵活决策
5. **认知思维链** - 不直接输出操作，而是先深度思考再决策

---

## 八、适用场景

### ✅ 最适合

- 复杂多步任务（如"在电商 App 完成购物流程"）
- UI 频繁变化的 App
- 需要处理各种异常情况（弹窗、加载、错误）
- 探索性任务（第一次接触某个 App）

### ❌ 不适合

- 简单单步操作（如"点击某个固定按钮"）
- 对延迟敏感的实时操作
- 资源受限环境（需要大模型支持）

---

**文档版本**: v1.0
**创建时间**: 2025-10-31
**类型**: 顶层架构设计
