# é•¿æœŸè®°å¿†ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ - Reflexion + Experience Replay

## ä¸€ã€ç³»ç»Ÿæ¦‚è¿°

æœ¬æ–¹æ¡ˆè®¾è®¡ä¸€ä¸ªåŸºäºç»éªŒå­¦ä¹ çš„é•¿æœŸè®°å¿†ç³»ç»Ÿï¼Œä½¿ Agent èƒ½å¤Ÿï¼š
1. **é¦–æ¬¡æ¢ç´¢**ï¼šé€šè¿‡ Reflexion å¾ªç¯æ¢ç´¢å¹¶å®Œæˆæ–°ä»»åŠ¡
2. **ç»éªŒæ²‰æ·€**ï¼šå°†æˆåŠŸçš„æ‰§è¡Œè·¯å¾„ä¿å­˜åˆ°é•¿æœŸè®°å¿†
3. **å¿«é€Ÿå¤ç”¨**ï¼šåç»­é‡åˆ°ç›¸ä¼¼ä»»åŠ¡æ—¶ç›´æ¥æ£€ç´¢å¹¶åº”ç”¨ç»éªŒ

### æ ¸å¿ƒç†å¿µ
> "ç¬¬ä¸€æ¬¡æ¢ç´¢ï¼Œç¬¬äºŒæ¬¡ç›´è¾¾"

---

## äºŒã€æ¶æ„è®¾è®¡

### 2.1 ç³»ç»Ÿåˆ†å±‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Task Input Layer               â”‚  ç”¨æˆ·ä»»åŠ¡è¾“å…¥
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Memory Retrieval Layer            â”‚  ç»éªŒæ£€ç´¢å±‚
â”‚   â”œâ”€ Task Embedding                 â”‚
â”‚   â”œâ”€ Similarity Search              â”‚
â”‚   â””â”€ Experience Matching            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Execution Strategy Layer          â”‚  æ‰§è¡Œç­–ç•¥å±‚
â”‚   â”œâ”€ Direct Replay (æœ‰ç»éªŒ)         â”‚
â”‚   â”œâ”€ Reflexion Explore (æ— ç»éªŒ)     â”‚
â”‚   â””â”€ Hybrid Mode (éƒ¨åˆ†åŒ¹é…)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Experience Learning Layer         â”‚  ç»éªŒå­¦ä¹ å±‚
â”‚   â”œâ”€ Success Pattern Extract        â”‚
â”‚   â”œâ”€ Memory Consolidation           â”‚
â”‚   â””â”€ Index Update                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Storage Layer                     â”‚  å­˜å‚¨å±‚
â”‚   â”œâ”€ Vector DB (ä»»åŠ¡è¯­ä¹‰ç´¢å¼•)       â”‚
â”‚   â”œâ”€ Graph DB (æ“ä½œåºåˆ—å›¾)          â”‚
â”‚   â””â”€ Key-Value Store (å…ƒæ•°æ®)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¸‰ã€æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 3.1 ä»»åŠ¡ç»éªŒå­˜å‚¨ç»“æ„

#### ç»éªŒè®°å½• Schema (Pydantic Model)

```python
from pydantic import BaseModel, Field
from typing import List, Dict, Optional
from datetime import datetime

class ActionStep(BaseModel):
    """å•ä¸ªæ“ä½œæ­¥éª¤"""
    step_id: int
    action_type: str  # click, swipe, input, wait
    target: str  # æ§ä»¶æè¿°æˆ–åæ ‡
    params: Dict  # æ“ä½œå‚æ•°
    screenshot_before: Optional[str] = None  # æˆªå›¾è·¯å¾„
    screenshot_after: Optional[str] = None
    success: bool = True
    duration_ms: int = 0

class TaskExperience(BaseModel):
    """ä»»åŠ¡ç»éªŒè®°å½•"""
    experience_id: str = Field(default_factory=lambda: str(uuid.uuid4()))

    # ä»»åŠ¡å…ƒæ•°æ®
    task_description: str  # "æ‰“å¼€æ·˜å®ï¼Œä¹°ä¸€ä¸ªåŒè‚©åŒ…"
    task_intent: str  # "è´­ç‰©"
    app_name: str  # "æ·˜å®"
    task_tags: List[str]  # ["è´­ç‰©", "æ·˜å®", "èƒŒåŒ…"]

    # æ‰§è¡Œè®°å½•
    action_sequence: List[ActionStep]  # æ“ä½œåºåˆ—
    total_steps: int
    total_duration_ms: int
    success_rate: float = 1.0  # åˆå§‹æˆåŠŸç‡

    # ä¸Šä¸‹æ–‡ä¿¡æ¯
    device_info: Dict  # è®¾å¤‡å‹å·ã€åˆ†è¾¨ç‡
    app_version: str
    ui_structure: Optional[str] = None  # å…³é”® UI å…ƒç´ æè¿°

    # å­¦ä¹ å…ƒæ•°æ®
    created_at: datetime = Field(default_factory=datetime.now)
    last_used_at: Optional[datetime] = None
    use_count: int = 0
    feedback_score: float = 0.0  # ç”¨æˆ·åé¦ˆè¯„åˆ†

    # å‘é‡ç´¢å¼•
    embedding: Optional[List[float]] = None  # ä»»åŠ¡æè¿°çš„è¯­ä¹‰å‘é‡

class ExperienceGraph(BaseModel):
    """ç»éªŒå›¾è°±ï¼ˆç”¨äºæ³›åŒ–ï¼‰"""
    graph_id: str
    task_pattern: str  # "åœ¨{app}æœç´¢{å•†å“}å¹¶ä¸‹å•"
    common_path: List[str]  # é€šç”¨è·¯å¾„èŠ‚ç‚¹
    variable_slots: Dict[str, str]  # å¯å˜æ§½ä½
    success_cases: List[str]  # æˆåŠŸæ¡ˆä¾‹ ID åˆ—è¡¨
```

---

### 3.2 å­˜å‚¨æ–¹æ¡ˆ

#### æ–¹æ¡ˆä¸€ï¼šè½»é‡çº§æ–¹æ¡ˆï¼ˆæ¨èå¿«é€Ÿå®ç°ï¼‰

```python
# ä½¿ç”¨ ChromaDB + SQLite ç»„åˆ

import chromadb
from chromadb.utils import embedding_functions

class MemoryStore:
    def __init__(self, persist_directory="./memory_db"):
        # å‘é‡å­˜å‚¨ï¼ˆè¯­ä¹‰æœç´¢ï¼‰
        self.chroma_client = chromadb.PersistentClient(path=persist_directory)
        self.embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="paraphrase-multilingual-MiniLM-L12-v2"
        )
        self.collection = self.chroma_client.get_or_create_collection(
            name="task_experiences",
            embedding_function=self.embedding_fn
        )

        # è¯¦ç»†æ•°æ®å­˜å‚¨ï¼ˆJSON æ–‡ä»¶æˆ– SQLiteï¼‰
        self.detail_store = f"{persist_directory}/experiences.db"

    def save_experience(self, experience: TaskExperience):
        """ä¿å­˜ç»éªŒ"""
        # 1. å­˜å‚¨å‘é‡ç´¢å¼•
        self.collection.add(
            ids=[experience.experience_id],
            documents=[experience.task_description],
            metadatas=[{
                "app_name": experience.app_name,
                "task_intent": experience.task_intent,
                "success_rate": experience.success_rate,
                "created_at": experience.created_at.isoformat()
            }]
        )

        # 2. å­˜å‚¨å®Œæ•´æ•°æ®ï¼ˆSQLite æˆ– JSONï¼‰
        self._save_to_detail_store(experience)

    def search_similar_tasks(self, query: str, top_k=5, threshold=0.7):
        """è¯­ä¹‰æœç´¢ç›¸ä¼¼ä»»åŠ¡"""
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k
        )

        # è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœ
        filtered = []
        for i, (id, distance) in enumerate(zip(results['ids'][0], results['distances'][0])):
            similarity = 1 - distance  # ChromaDB è¿”å›è·ç¦»ï¼Œè½¬æ¢ä¸ºç›¸ä¼¼åº¦
            if similarity >= threshold:
                filtered.append({
                    "experience_id": id,
                    "similarity": similarity,
                    "metadata": results['metadatas'][0][i]
                })

        return filtered
```

#### æ–¹æ¡ˆäºŒï¼šé«˜çº§æ–¹æ¡ˆï¼ˆå¤§è§„æ¨¡åº”ç”¨ï¼‰

```
Storage Stack:
â”œâ”€ Qdrant / Milvus - å‘é‡æ•°æ®åº“ï¼ˆç™¾ä¸‡çº§è¯­ä¹‰æœç´¢ï¼‰
â”œâ”€ Neo4j - å›¾æ•°æ®åº“ï¼ˆä»»åŠ¡ä¾èµ–å…³ç³»ã€æ³›åŒ–æ¨¡å¼ï¼‰
â””â”€ PostgreSQL - å…³ç³»æ•°æ®åº“ï¼ˆå…ƒæ•°æ®ã€ç»Ÿè®¡åˆ†æï¼‰
```

---

### 3.3 ç»éªŒæ£€ç´¢ä¸åŒ¹é…ç®—æ³•

#### å¤šçº§æ£€ç´¢ç­–ç•¥

```python
class ExperienceRetriever:
    def __init__(self, memory_store: MemoryStore):
        self.store = memory_store

    def retrieve(self, task_description: str) -> RetrievalResult:
        """
        ä¸‰çº§æ£€ç´¢ç­–ç•¥ï¼š
        1. ç²¾ç¡®åŒ¹é…ï¼ˆå“ˆå¸Œï¼‰
        2. è¯­ä¹‰ç›¸ä¼¼ï¼ˆå‘é‡ï¼‰
        3. æ¨¡å¼åŒ¹é…ï¼ˆå›¾è°±ï¼‰
        """

        # Level 1: ç²¾ç¡®åŒ¹é…ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
        exact_match = self._exact_match(task_description)
        if exact_match and exact_match.success_rate > 0.9:
            return RetrievalResult(
                match_type="exact",
                experience=exact_match,
                confidence=1.0,
                strategy="direct_replay"
            )

        # Level 2: è¯­ä¹‰ç›¸ä¼¼åŒ¹é…
        similar_tasks = self.store.search_similar_tasks(
            task_description,
            top_k=5,
            threshold=0.75
        )

        if similar_tasks:
            best_match = similar_tasks[0]
            if best_match['similarity'] > 0.85:
                experience = self._load_experience(best_match['experience_id'])
                return RetrievalResult(
                    match_type="semantic",
                    experience=experience,
                    confidence=best_match['similarity'],
                    strategy="adaptive_replay"  # éœ€è¦è½»å¾®è°ƒæ•´
                )

        # Level 3: æ¨¡å¼åŒ¹é…ï¼ˆæ³›åŒ–æ£€ç´¢ï¼‰
        pattern_match = self._pattern_match(task_description)
        if pattern_match:
            return RetrievalResult(
                match_type="pattern",
                experience=pattern_match,
                confidence=0.6,
                strategy="guided_exploration"  # ä½¿ç”¨æ¨¡æ¿å¼•å¯¼æ¢ç´¢
            )

        # æ— åŒ¹é…ï¼šå…¨æ–°æ¢ç´¢
        return RetrievalResult(
            match_type="none",
            experience=None,
            confidence=0.0,
            strategy="reflexion_explore"
        )

    def _exact_match(self, task: str) -> Optional[TaskExperience]:
        """ç²¾ç¡®åŒ¹é…ï¼ˆé€šè¿‡ä»»åŠ¡æè¿°å“ˆå¸Œï¼‰"""
        task_hash = hashlib.md5(task.encode()).hexdigest()
        return self.store.get_by_hash(task_hash)

    def _pattern_match(self, task: str) -> Optional[ExperienceGraph]:
        """
        æ¨¡å¼åŒ¹é…ç¤ºä¾‹ï¼š
        è¾“å…¥ï¼š"æ‰“å¼€äº¬ä¸œï¼Œä¹°ä¸€ä¸ªé”®ç›˜"
        åŒ¹é…æ¨¡å¼ï¼š"åœ¨{app}æœç´¢{å•†å“}å¹¶ä¸‹å•"
        æå–æ§½ä½ï¼šapp=äº¬ä¸œ, å•†å“=é”®ç›˜
        """
        # ä½¿ç”¨ NER æå–å®ä½“
        entities = self._extract_entities(task)

        # æŸ¥è¯¢å›¾æ•°æ®åº“ä¸­çš„æ¨¡å¼
        for pattern in self.store.get_patterns():
            if self._match_pattern(pattern, entities):
                return pattern
        return None
```

#### ç›¸ä¼¼åº¦è®¡ç®—ä¼˜åŒ–

```python
def compute_task_similarity(task1: str, task2: str, context: Dict) -> float:
    """
    ç»¼åˆç›¸ä¼¼åº¦è®¡ç®—ï¼š
    - è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆ70%ï¼‰
    - App åŒ¹é…åº¦ï¼ˆ15%ï¼‰
    - æ„å›¾åŒ¹é…åº¦ï¼ˆ15%ï¼‰
    """

    # 1. è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰
    semantic_sim = cosine_similarity(
        embedding_model.encode(task1),
        embedding_model.encode(task2)
    )

    # 2. App åŒ¹é…
    app_sim = 1.0 if extract_app(task1) == extract_app(task2) else 0.0

    # 3. æ„å›¾åŒ¹é…ï¼ˆè´­ç‰©ã€ç¤¾äº¤ã€å¨±ä¹ç­‰ï¼‰
    intent_sim = intent_classifier.similarity(task1, task2)

    # åŠ æƒç»¼åˆ
    return 0.7 * semantic_sim + 0.15 * app_sim + 0.15 * intent_sim
```

---

### 3.4 ç»éªŒå­¦ä¹ ä¸ä¼˜åŒ–æœºåˆ¶

#### ç»éªŒæå–æµç¨‹

```python
class ExperienceLearner:
    def extract_from_execution(
        self,
        task_description: str,
        execution_trace: ExecutionTrace,
        final_state: AgentState
    ) -> TaskExperience:
        """
        ä» Reflexion æ‰§è¡ŒæˆåŠŸåæå–ç»éªŒ
        """

        # 1. æå–å…³é”®æ“ä½œåºåˆ—ï¼ˆå»é™¤å†—ä½™æ­¥éª¤ï¼‰
        cleaned_actions = self._remove_redundant_steps(
            execution_trace.actions
        )

        # 2. æ ‡æ³¨å…³é”®å†³ç­–ç‚¹
        annotated_actions = self._annotate_decision_points(
            cleaned_actions,
            execution_trace.screenshots
        )

        # 3. æå– UI å…ƒç´ ç‰¹å¾ï¼ˆç”¨äºåç»­å®šä½ï¼‰
        ui_features = self._extract_ui_features(
            execution_trace.screenshots,
            annotated_actions
        )

        # 4. æ„å»ºç»éªŒå¯¹è±¡
        experience = TaskExperience(
            task_description=task_description,
            task_intent=self._classify_intent(task_description),
            app_name=self._extract_app_name(task_description),
            task_tags=self._generate_tags(task_description),
            action_sequence=annotated_actions,
            total_steps=len(annotated_actions),
            ui_structure=ui_features,
            device_info=final_state.device_info
        )

        # 5. ç”Ÿæˆè¯­ä¹‰å‘é‡
        experience.embedding = self._generate_embedding(task_description)

        return experience

    def _remove_redundant_steps(self, actions: List[ActionStep]) -> List[ActionStep]:
        """
        å»é™¤å†—ä½™æ­¥éª¤ï¼š
        - é‡å¤ç‚¹å‡»
        - æ— æ•ˆç­‰å¾…
        - é”™è¯¯åå›é€€çš„æ“ä½œ
        """
        cleaned = []
        for i, action in enumerate(actions):
            # æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤æ“ä½œ
            if i > 0 and self._is_duplicate(action, actions[i-1]):
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å°è¯•
            if action.metadata.get("is_correction", False):
                continue

            cleaned.append(action)

        return cleaned

    def _annotate_decision_points(
        self,
        actions: List[ActionStep],
        screenshots: List[str]
    ) -> List[ActionStep]:
        """
        æ ‡æ³¨å…³é”®å†³ç­–ç‚¹ï¼š
        - é¡µé¢è·³è½¬ç‚¹
        - æœç´¢è¾“å…¥ç‚¹
        - ç¡®è®¤æ“ä½œç‚¹
        """
        for i, action in enumerate(actions):
            # ä½¿ç”¨è§†è§‰æ¨¡å‹åˆ¤æ–­é¡µé¢å˜åŒ–
            if i > 0 and self._detect_page_change(screenshots[i-1], screenshots[i]):
                action.metadata["is_decision_point"] = True
                action.metadata["decision_type"] = "page_transition"

            # æ ‡æ³¨è¾“å…¥ç±»æ“ä½œ
            if action.action_type == "input":
                action.metadata["is_decision_point"] = True
                action.metadata["decision_type"] = "user_input"

        return actions
```

#### ç»éªŒä¼˜åŒ–ä¸æ³›åŒ–

```python
class ExperienceOptimizer:
    def generalize_experiences(self, experiences: List[TaskExperience]):
        """
        ä»å¤šä¸ªç›¸ä¼¼ç»éªŒä¸­æå–é€šç”¨æ¨¡å¼

        ç¤ºä¾‹ï¼š
        - "æ‰“å¼€æ·˜å®ä¹°åŒè‚©åŒ…" + "æ‰“å¼€æ·˜å®ä¹°é”®ç›˜" + "æ‰“å¼€æ·˜å®ä¹°æ‰‹æœº"
        â†’ æ³›åŒ–ä¸ºï¼š"åœ¨æ·˜å®æœç´¢{å•†å“}å¹¶ä¸‹å•" æ¨¡å¼
        """

        # 1. èšç±»ç›¸ä¼¼ä»»åŠ¡
        clusters = self._cluster_by_pattern(experiences)

        # 2. æ¯ä¸ªèšç±»æå–å…¬å…±è·¯å¾„
        for cluster in clusters:
            common_path = self._extract_common_path(cluster)
            variable_slots = self._identify_variable_slots(cluster)

            # 3. åˆ›å»ºç»éªŒå›¾è°±
            pattern = ExperienceGraph(
                graph_id=str(uuid.uuid4()),
                task_pattern=self._generate_pattern_template(common_path, variable_slots),
                common_path=common_path,
                variable_slots=variable_slots,
                success_cases=[exp.experience_id for exp in cluster]
            )

            # 4. ä¿å­˜åˆ°å›¾æ•°æ®åº“
            self.graph_store.save_pattern(pattern)

    def update_success_rate(self, experience_id: str, success: bool):
        """
        æ›´æ–°ç»éªŒæˆåŠŸç‡ï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰
        """
        experience = self.store.get(experience_id)

        # ä½¿ç”¨ EMA å¹³æ»‘æ›´æ–°
        alpha = 0.3  # å­¦ä¹ ç‡
        new_rate = alpha * (1.0 if success else 0.0) + (1 - alpha) * experience.success_rate

        experience.success_rate = new_rate
        experience.use_count += 1
        experience.last_used_at = datetime.now()

        self.store.update(experience)

        # å¦‚æœæˆåŠŸç‡è¿‡ä½ï¼Œæ ‡è®°ä¸ºéœ€è¦é‡æ–°æ¢ç´¢
        if new_rate < 0.5:
            self._mark_for_relearn(experience_id)
```

---

## å››ã€é›†æˆåˆ° LangGraph å·¥ä½œæµ

### 4.1 å¢å¼ºçš„å·¥ä½œæµè®¾è®¡

```python
from langgraph.graph import StateGraph, END

def build_memory_enhanced_graph():
    """æ„å»ºå¸¦é•¿æœŸè®°å¿†çš„ LangGraph"""

    graph = StateGraph(AgentState)

    # ========== æ–°å¢èŠ‚ç‚¹ ==========
    graph.add_node("memory_retrieve", memory_retrieve_node)  # ç»éªŒæ£€ç´¢
    graph.add_node("experience_learn", experience_learn_node)  # ç»éªŒå­¦ä¹ 

    # ========== åŸæœ‰èŠ‚ç‚¹ ==========
    graph.add_node("capture", capture_node)
    graph.add_node("analyze", analyze_node)
    graph.add_node("generate_code", generate_code_node)
    graph.add_node("execute", execute_node)
    graph.add_node("verify", verify_node)

    # ========== æ–°å¢è¾¹ ==========
    graph.set_entry_point("memory_retrieve")

    # ç»éªŒæ£€ç´¢åçš„è·¯ç”±
    graph.add_conditional_edges(
        "memory_retrieve",
        route_by_memory_match,
        {
            "direct_replay": "execute",           # ç›´æ¥å¤ç”¨ç»éªŒ
            "adaptive_replay": "analyze",         # è½»å¾®è°ƒæ•´åæ‰§è¡Œ
            "guided_exploration": "capture",      # ä½¿ç”¨æ¨¡æ¿å¼•å¯¼
            "reflexion_explore": "capture"        # å®Œå…¨æ–°æ¢ç´¢
        }
    )

    # åŸæœ‰ Reflexion å¾ªç¯
    graph.add_edge("capture", "analyze")
    graph.add_edge("analyze", "generate_code")
    graph.add_edge("generate_code", "execute")
    graph.add_edge("execute", "verify")

    graph.add_conditional_edges(
        "verify",
        route_verification,
        {
            "success": "experience_learn",  # æˆåŠŸåå­¦ä¹ ç»éªŒ
            "retry": "analyze",             # å¤±è´¥é‡è¯•
            "fail": END
        }
    )

    # ç»éªŒå­¦ä¹ åç»“æŸ
    graph.add_edge("experience_learn", END)

    return graph.compile()
```

### 4.2 å…³é”®èŠ‚ç‚¹å®ç°

#### ç»éªŒæ£€ç´¢èŠ‚ç‚¹

```python
async def memory_retrieve_node(state: AgentState) -> AgentState:
    """ç»éªŒæ£€ç´¢èŠ‚ç‚¹"""

    task = state["user_request"]

    # 1. æ£€ç´¢ç›¸ä¼¼ç»éªŒ
    retriever = ExperienceRetriever(memory_store)
    result = retriever.retrieve(task)

    # 2. æ›´æ–°çŠ¶æ€
    state["memory_match"] = result
    state["execution_strategy"] = result.strategy

    # 3. å¦‚æœæœ‰é«˜ç½®ä¿¡åº¦åŒ¹é…ï¼Œé¢„åŠ è½½æ“ä½œåºåˆ—
    if result.confidence > 0.8 and result.experience:
        state["suggested_actions"] = result.experience.action_sequence
        state["context"]["from_memory"] = True

        logger.info(
            f"ğŸ“š æ‰¾åˆ°åŒ¹é…ç»éªŒ (ç›¸ä¼¼åº¦: {result.confidence:.2f}), "
            f"ç­–ç•¥: {result.strategy}"
        )
    else:
        logger.info("ğŸ” æ— åŒ¹é…ç»éªŒï¼Œå¯åŠ¨æ¢ç´¢æ¨¡å¼")
        state["context"]["from_memory"] = False

    return state
```

#### ç»éªŒå­¦ä¹ èŠ‚ç‚¹

```python
async def experience_learn_node(state: AgentState) -> AgentState:
    """ç»éªŒå­¦ä¹ èŠ‚ç‚¹ï¼ˆæˆåŠŸåè°ƒç”¨ï¼‰"""

    # ä»…åœ¨ Reflexion æ¢ç´¢æˆåŠŸåå­¦ä¹ ï¼ˆé¿å…é‡å¤å­¦ä¹ ï¼‰
    if state["context"].get("from_memory", False):
        logger.info("âœ… ä½¿ç”¨å·²æœ‰ç»éªŒå®Œæˆï¼Œè·³è¿‡å­¦ä¹ ")
        return state

    # 1. æå–ç»éªŒ
    learner = ExperienceLearner()
    experience = learner.extract_from_execution(
        task_description=state["user_request"],
        execution_trace=state["execution_history"],
        final_state=state
    )

    # 2. ä¿å­˜åˆ°é•¿æœŸè®°å¿†
    memory_store.save_experience(experience)

    logger.info(
        f"ğŸ§  å­¦ä¹ æ–°ç»éªŒ: {experience.experience_id}\n"
        f"   ä»»åŠ¡: {experience.task_description}\n"
        f"   æ­¥éª¤æ•°: {experience.total_steps}\n"
        f"   è€—æ—¶: {experience.total_duration_ms}ms"
    )

    # 3. å¼‚æ­¥è§¦å‘æ³›åŒ–ä»»åŠ¡ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
    asyncio.create_task(
        optimizer.try_generalize(experience.experience_id)
    )

    state["learned_experience_id"] = experience.experience_id

    return state
```

#### è·¯ç”±é€»è¾‘

```python
def route_by_memory_match(state: AgentState) -> str:
    """æ ¹æ®ç»éªŒåŒ¹é…ç»“æœè·¯ç”±"""

    match_result = state["memory_match"]
    strategy = match_result.strategy

    # é«˜ç½®ä¿¡åº¦ç›´æ¥æ‰§è¡Œ
    if strategy == "direct_replay" and match_result.confidence > 0.9:
        logger.info("ğŸš€ ç›´æ¥å¤ç”¨ç»éªŒæ‰§è¡Œ")
        return "direct_replay"

    # ä¸­ç­‰ç½®ä¿¡åº¦åšè½»å¾®è°ƒæ•´
    elif strategy == "adaptive_replay" and match_result.confidence > 0.75:
        logger.info("ğŸ”§ è°ƒæ•´ç»éªŒåæ‰§è¡Œ")
        return "adaptive_replay"

    # æœ‰æ¨¡å¼å¼•å¯¼
    elif strategy == "guided_exploration":
        logger.info("ğŸ—ºï¸ ä½¿ç”¨æ¨¡æ¿å¼•å¯¼æ¢ç´¢")
        return "guided_exploration"

    # å®Œå…¨æ¢ç´¢
    else:
        logger.info("ğŸ”¬ å¯åŠ¨ Reflexion æ¢ç´¢")
        return "reflexion_explore"
```

---

## äº”ã€æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 5.1 æ£€ç´¢ä¼˜åŒ–

```python
# 1. å¤šçº§ç¼“å­˜
class CachedRetriever:
    def __init__(self):
        self.l1_cache = LRUCache(maxsize=100)  # å†…å­˜ç¼“å­˜
        self.l2_cache = RedisCache()           # Redis ç¼“å­˜
        self.store = MemoryStore()             # æŒä¹…åŒ–å­˜å‚¨

    def retrieve(self, task: str):
        # L1: å†…å­˜
        if task in self.l1_cache:
            return self.l1_cache[task]

        # L2: Redis
        cached = self.l2_cache.get(task)
        if cached:
            self.l1_cache[task] = cached
            return cached

        # L3: æ•°æ®åº“
        result = self.store.search_similar_tasks(task)
        self.l2_cache.set(task, result, ttl=3600)
        self.l1_cache[task] = result
        return result

# 2. æ‰¹é‡é¢„åŠ è½½
async def preload_frequent_tasks():
    """å¯åŠ¨æ—¶é¢„åŠ è½½é«˜é¢‘ä»»åŠ¡"""
    top_tasks = memory_store.get_top_used_tasks(limit=50)
    for task in top_tasks:
        await retriever.prefetch(task.experience_id)
```

### 5.2 å‘é‡ç´¢å¼•ä¼˜åŒ–

```python
# ä½¿ç”¨ HNSW ç´¢å¼•åŠ é€Ÿæ£€ç´¢
collection = client.create_collection(
    name="task_experiences",
    metadata={
        "hnsw:space": "cosine",
        "hnsw:M": 16,              # è¿æ¥æ•°
        "hnsw:ef_construction": 200  # æ„å»ºæ—¶ç²¾åº¦
    }
)
```

---

## å…­ã€å®æ–½è·¯çº¿å›¾

### Phase 1: MVPï¼ˆ1-2 å‘¨ï¼‰
- [ ] å®ç° `TaskExperience` å’Œ `MemoryStore` åŸºç¡€ç±»
- [ ] é›†æˆ ChromaDB åšè¯­ä¹‰æœç´¢
- [ ] å®ç° `memory_retrieve` å’Œ `experience_learn` èŠ‚ç‚¹
- [ ] åŸºç¡€ç²¾ç¡®åŒ¹é…å’Œè¯­ä¹‰åŒ¹é…

### Phase 2: ä¼˜åŒ–ï¼ˆ2-3 å‘¨ï¼‰
- [ ] å®ç°ç»éªŒä¼˜åŒ–ç®—æ³•ï¼ˆå»å†—ä½™ã€æ ‡æ³¨å†³ç­–ç‚¹ï¼‰
- [ ] æ·»åŠ æˆåŠŸç‡è¿½è¸ªå’Œè‡ªåŠ¨æ·˜æ±°æœºåˆ¶
- [ ] å®ç°å¤šçº§ç¼“å­˜
- [ ] æ·»åŠ ç›‘æ§å’Œç»Ÿè®¡é¢æ¿

### Phase 3: é«˜çº§ç‰¹æ€§ï¼ˆ3-4 å‘¨ï¼‰
- [ ] å®ç°ç»éªŒæ³›åŒ–ï¼ˆæ¨¡å¼æå–ï¼‰
- [ ] é›†æˆå›¾æ•°æ®åº“åšæ¨¡å¼åŒ¹é…
- [ ] å®ç°è·¨è®¾å¤‡ç»éªŒè¿ç§»
- [ ] æ·»åŠ ç”¨æˆ·åé¦ˆå¾ªç¯

---

## ä¸ƒã€ç¤ºä¾‹ï¼šå®Œæ•´æµç¨‹æ¼”ç¤º

### é¦–æ¬¡æ‰§è¡Œï¼ˆReflexion æ¢ç´¢ï¼‰

```python
# ç”¨æˆ·è¾“å…¥
task = "æ‰“å¼€æ·˜å®ï¼Œä¹°ä¸€ä¸ªåŒè‚©åŒ…"

# 1. memory_retrieve: æ— åŒ¹é…ç»éªŒ
retrieval_result = {
    "match_type": "none",
    "confidence": 0.0,
    "strategy": "reflexion_explore"
}

# 2. capture â†’ analyze â†’ generate â†’ execute â†’ verify
# ... Reflexion å¾ªç¯æ‰§è¡Œ ...
# æœ€ç»ˆæˆåŠŸï¼Œæ‰§è¡Œäº† 15 ä¸ªæ­¥éª¤

# 3. experience_learn: ä¿å­˜ç»éªŒ
experience = TaskExperience(
    experience_id="exp_abc123",
    task_description="æ‰“å¼€æ·˜å®ï¼Œä¹°ä¸€ä¸ªåŒè‚©åŒ…",
    task_intent="è´­ç‰©",
    app_name="æ·˜å®",
    action_sequence=[
        ActionStep(action_type="click", target="æ·˜å®å›¾æ ‡", ...),
        ActionStep(action_type="input", target="æœç´¢æ¡†", params={"text": "åŒè‚©åŒ…"}),
        ActionStep(action_type="click", target="æœç´¢æŒ‰é’®", ...),
        # ... å…± 15 æ­¥ ...
    ],
    total_steps=15,
    total_duration_ms=12000,
    success_rate=1.0
)

memory_store.save_experience(experience)
# âœ… ä¿å­˜æˆåŠŸï¼Œç”Ÿæˆå‘é‡ç´¢å¼•
```

### ç¬¬äºŒæ¬¡æ‰§è¡Œï¼ˆç›´æ¥å¤ç”¨ï¼‰

```python
# ç”¨æˆ·è¾“å…¥ï¼ˆç›¸åŒä»»åŠ¡ï¼‰
task = "æ‰“å¼€æ·˜å®ï¼Œä¹°ä¸€ä¸ªåŒè‚©åŒ…"

# 1. memory_retrieve: æ‰¾åˆ°ç²¾ç¡®åŒ¹é…
retrieval_result = {
    "match_type": "exact",
    "experience": experience,  # ä¸Šæ¬¡ä¿å­˜çš„ç»éªŒ
    "confidence": 1.0,
    "strategy": "direct_replay"
}

# 2. ç›´æ¥è·³è½¬åˆ° execute èŠ‚ç‚¹
# æŒ‰ç…§ experience.action_sequence æ‰§è¡Œ
for action in experience.action_sequence:
    execute_action(action)

# 3. verify: éªŒè¯æˆåŠŸ
# 4. æ›´æ–°ç»éªŒå…ƒæ•°æ®
experience.use_count += 1
experience.last_used_at = datetime.now()

# âœ… å®Œæˆï¼è€—æ—¶ä» 12 ç§’é™ä½åˆ° 3 ç§’
```

### ç›¸ä¼¼ä»»åŠ¡æ‰§è¡Œï¼ˆè¯­ä¹‰åŒ¹é… + è°ƒæ•´ï¼‰

```python
# ç”¨æˆ·è¾“å…¥ï¼ˆç›¸ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒï¼‰
task = "æ‰“å¼€æ·˜å®ï¼Œä¹°ä¸€ä¸ªé”®ç›˜"

# 1. memory_retrieve: æ‰¾åˆ°è¯­ä¹‰ç›¸ä¼¼ç»éªŒ
retrieval_result = {
    "match_type": "semantic",
    "experience": experience,  # "ä¹°åŒè‚©åŒ…"çš„ç»éªŒ
    "confidence": 0.87,
    "strategy": "adaptive_replay"
}

# 2. analyze: è½»é‡çº§è°ƒæ•´
# è¯†åˆ«å·®å¼‚ï¼šæœç´¢è¯ä»"åŒè‚©åŒ…"å˜ä¸º"é”®ç›˜"
adjusted_actions = adjust_actions(
    experience.action_sequence,
    changes={"æœç´¢æ–‡æœ¬": "é”®ç›˜"}
)

# 3. execute: æ‰§è¡Œè°ƒæ•´åçš„æ“ä½œ
for action in adjusted_actions:
    execute_action(action)

# 4. verify: æˆåŠŸ
# 5. experience_learn: ä¿å­˜æ–°ç»éªŒï¼ˆå¯é€‰ï¼‰
# æˆ–è€…æ›´æ–°åŸç»éªŒçš„æˆåŠŸç‡

# âœ… å®Œæˆï¼åˆ©ç”¨äº† 80% çš„åŸæœ‰ç»éªŒ
```

---

## å…«ã€ç›‘æ§ä¸è¯„ä¼°æŒ‡æ ‡

### å…³é”®æŒ‡æ ‡

```python
class MemoryMetrics:
    """é•¿æœŸè®°å¿†ç³»ç»ŸæŒ‡æ ‡"""

    # æ£€ç´¢æ•ˆç‡
    retrieval_hit_rate: float        # å‘½ä¸­ç‡
    avg_retrieval_time_ms: float     # å¹³å‡æ£€ç´¢è€—æ—¶

    # æ‰§è¡Œæ•ˆç‡
    replay_success_rate: float       # å¤ç”¨æˆåŠŸç‡
    avg_speedup_factor: float        # å¹³å‡åŠ é€Ÿå€æ•°

    # å­¦ä¹ è´¨é‡
    experience_reuse_count: Dict[str, int]  # ç»éªŒå¤ç”¨æ¬¡æ•°
    experience_decay_rate: float            # ç»éªŒè¡°å‡ç‡
    generalization_accuracy: float          # æ³›åŒ–å‡†ç¡®ç‡

    # å­˜å‚¨
    total_experiences: int
    avg_experience_size_kb: float
    storage_growth_rate: float
```

### ç›‘æ§é¢æ¿

```python
# å®æ—¶ç›‘æ§
def print_memory_stats():
    stats = memory_store.get_statistics()

    print(f"""
    ğŸ“Š é•¿æœŸè®°å¿†ç³»ç»Ÿç»Ÿè®¡
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ğŸ“š æ€»ç»éªŒæ•°: {stats.total_experiences}
    ğŸ¯ å‘½ä¸­ç‡: {stats.retrieval_hit_rate:.1%}
    âš¡ å¹³å‡åŠ é€Ÿ: {stats.avg_speedup_factor:.1f}x
    âœ… å¤ç”¨æˆåŠŸç‡: {stats.replay_success_rate:.1%}

    ğŸ”¥ çƒ­é—¨ä»»åŠ¡ TOP 5:
    {format_top_tasks(stats.top_tasks)}

    ğŸ•’ æœ€è¿‘å­¦ä¹ :
    {format_recent_learns(stats.recent_experiences)}
    """)
```

---

## ä¹ã€æ³¨æ„äº‹é¡¹ä¸æœ€ä½³å®è·µ

### éšç§ä¸å®‰å…¨

```python
class PrivacyFilter:
    """éšç§è¿‡æ»¤å™¨ï¼šé¿å…è®°å¿†æ•æ„Ÿä¿¡æ¯"""

    SENSITIVE_FIELDS = ["password", "credit_card", "id_number"]

    def filter_experience(self, experience: TaskExperience):
        """è¿‡æ»¤æ•æ„Ÿå­—æ®µ"""
        for action in experience.action_sequence:
            if action.action_type == "input":
                # æ£€æµ‹æ•æ„Ÿè¾“å…¥
                if self._is_sensitive(action.target):
                    action.params["text"] = "[REDACTED]"
                    action.metadata["contains_sensitive"] = True

        return experience
```

### ç‰ˆæœ¬å…¼å®¹

```python
# App ç‰ˆæœ¬å˜åŒ–æ—¶çš„å¤„ç†
def check_experience_compatibility(experience: TaskExperience, current_version: str):
    """æ£€æŸ¥ç»éªŒæ˜¯å¦é€‚ç”¨äºå½“å‰ App ç‰ˆæœ¬"""

    if experience.app_version != current_version:
        # å°è¯•æ‰§è¡Œï¼Œå¤±è´¥åæ ‡è®°ä¸ºè¿‡æœŸ
        return "experimental"  # å®éªŒæ€§å¤ç”¨

    return "compatible"
```

### ç»éªŒè¡°å‡ç­–ç•¥

```python
# å®šæœŸæ¸…ç†ä½ä»·å€¼ç»éªŒ
async def cleanup_stale_experiences():
    """æ¸…ç†è¿‡æœŸç»éªŒ"""

    cutoff_date = datetime.now() - timedelta(days=90)

    stale_experiences = memory_store.query(
        filters={
            "last_used_at": {"$lt": cutoff_date},
            "success_rate": {"$lt": 0.5}
        }
    )

    for exp in stale_experiences:
        logger.info(f"ğŸ—‘ï¸ æ¸…ç†è¿‡æœŸç»éªŒ: {exp.experience_id}")
        memory_store.delete(exp.experience_id)
```

---

## åã€æ€»ç»“

æœ¬æ–¹æ¡ˆå®ç°äº†ä¸€ä¸ªå®Œæ•´çš„é•¿æœŸè®°å¿†ç³»ç»Ÿï¼Œæ ¸å¿ƒç‰¹ç‚¹ï¼š

1. **æ™ºèƒ½æ£€ç´¢**ï¼šä¸‰çº§æ£€ç´¢ç­–ç•¥ï¼ˆç²¾ç¡®/è¯­ä¹‰/æ¨¡å¼ï¼‰
2. **è‡ªåŠ¨å­¦ä¹ **ï¼šæˆåŠŸåè‡ªåŠ¨æå–å’Œä¿å­˜ç»éªŒ
3. **åŠ¨æ€ä¼˜åŒ–**ï¼šæˆåŠŸç‡è¿½è¸ªã€ç»éªŒæ³›åŒ–ã€è‡ªåŠ¨æ·˜æ±°
4. **æ— ç¼é›†æˆ**ï¼šä¸ç°æœ‰ Reflexion + LangGraph å·¥ä½œæµå®Œç¾ç»“åˆ

### é¢„æœŸæ•ˆæœ

| åœºæ™¯ | é¦–æ¬¡æ‰§è¡Œ | ç¬¬äºŒæ¬¡æ‰§è¡Œ | åŠ é€Ÿæ¯” |
|-----|---------|-----------|-------|
| ç®€å•ä»»åŠ¡ | 5-10 ç§’ | 1-2 ç§’ | 5x |
| å¤æ‚ä»»åŠ¡ | 30-60 ç§’ | 5-10 ç§’ | 6x |
| è¶…å¤æ‚ä»»åŠ¡ | 2-5 åˆ†é’Ÿ | 20-40 ç§’ | 8x |

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. å…ˆå®ç° MVP ç‰ˆæœ¬ï¼ˆChromaDB + åŸºç¡€æ£€ç´¢ï¼‰
2. åœ¨çœŸå®åœºæ™¯æµ‹è¯•éªŒè¯
3. æ ¹æ®åé¦ˆè¿­ä»£ä¼˜åŒ–
4. é€æ­¥æ·»åŠ é«˜çº§ç‰¹æ€§ï¼ˆæ³›åŒ–ã€å›¾æ•°æ®åº“ç­‰ï¼‰

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¶é—´**: 2025-10-31
**ç»´æŠ¤è€…**: DroidRun-VL Team
